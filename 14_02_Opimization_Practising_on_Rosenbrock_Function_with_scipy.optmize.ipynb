{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practising Optimization on Rosenbrock function with 2 and n variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with minimize in scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - lambdify to value a derivative at a point x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - calculating Gradient Vector and Hessian Matrix of a 2 and n Variable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - check at \"minimized point\", both function and Gradient are ZERO! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - check at \"minimized point\", the Hessiam Matrix is positive definite (and semi - positive definite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sympy import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*x\n"
     ]
    }
   ],
   "source": [
    "x = Symbol('x')\n",
    "y = Symbol('y')\n",
    "z = x**2 + 1\n",
    "zprime = z.diff(x)\n",
    "print (zprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[2. 2. 2. 2. 2.]\n",
      "[105.   2.   2.   2.  10.]\n",
      "105.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print ccv[-1]\\nprint ccv[1:-1] # dal secondo al penultimo\\nprint ccv[1:]   # dal secondo all ultimo\\nprint ccv[:-1]  # dal primo al penultimo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f   = lambdify(x, zprime, 'numpy')\n",
    "print (f(10)) # value the derivative at x = 10\n",
    "ccv = f(np.ones(5)) # value the derivative at x = 1, for 5 times\n",
    "print (ccv)\n",
    "ccv[0] = 105\n",
    "ccv[-1] = 10\n",
    "print (ccv)\n",
    "print (ccv[0])\n",
    "'''print ccv[-1]\n",
    "print ccv[1:-1] # dal secondo al penultimo\n",
    "print ccv[1:]   # dal secondo all ultimo\n",
    "print ccv[:-1]  # dal primo al penultimo'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-400*x1*(-x1**2 + x2) + 2*x1 - 2\n",
      "-200*x1**2 + 200*x2\n",
      "1200*x1**2 - 400*x2 + 2\n",
      "-400*x1\n",
      "200\n",
      "-400*x1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x2 = Symbol('x2')\n",
    "x1 = Symbol('x1')\n",
    "\n",
    "# 2 variable function f(x1, x2)\n",
    "f  = 100*(x2 - x1**2)**2 + (1-x1)**2\n",
    "\n",
    "# 1st derivatives - Gradient Vector\n",
    "fprimex1 = f.diff(x1)\n",
    "fprimex2 = f.diff(x2)\n",
    "\n",
    "# 2nd derivatives  - Hessiam Matrix\n",
    "fprimex11 = fprimex1.diff(x1)\n",
    "fprimex22 = fprimex2.diff(x2)\n",
    "fprimex12 = fprimex1.diff(x2)\n",
    "fprimex21 = fprimex2.diff(x1)\n",
    "\n",
    "print (fprimex1)\n",
    "print (fprimex2)\n",
    "print (fprimex11)\n",
    "print (fprimex12)\n",
    "print (fprimex22)\n",
    "print (fprimex21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen(x):\n",
    "    \"\"\"The Rosenbrock function\"\"\"    \n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    return 100.0*(x2-x1**2.0)**2.0 + (1-x1)**2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 79\n",
      "         Function evaluations: 150\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([1.3, 0.7])\n",
    "res = minimize(rosen, x0, method='nelder-mead',options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[1.        , 1.        ],\n",
       "       [1.        , 0.99999999],\n",
       "       [1.        , 1.        ]]), array([3.37360776e-18, 9.41642436e-18, 2.25070018e-17]))\n",
       "           fun: 3.3736077629532093e-18\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 150\n",
       "           nit: 79\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "3.3736077629532093e-18\n"
     ]
    }
   ],
   "source": [
    "print(res.x)\n",
    "print(res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 110\n",
      "         Function evaluations: 206\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([0, 0])\n",
    "res = minimize(rosen, x0, method='nelder-mead',options={'xtol': 1e-8, 'disp': True})\n",
    "print(res.x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.650458998741964e-18\n",
      "2.650458998741964e-18\n"
     ]
    }
   ],
   "source": [
    "print(res.fun)\n",
    "print (rosen(res.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.751595186883519e-09\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "v2 = np.array([0.9999564, 0.9999085])\n",
    "print (rosen(v2))\n",
    "v2 = np.array([1., 1.])\n",
    "print (rosen(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the Gradient vector \n",
    "def rosen_der(x):\n",
    "    der = np.zeros_like(x)\n",
    "    der[0] = -400*x[0]*(x[1] -x[0]**2 ) + 2*x[0] - 2\n",
    "    der[1] = 200*(x[1] -x[0]**2)\n",
    "    return der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 19\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n"
     ]
    }
   ],
   "source": [
    "res2 = minimize(rosen, x0, method='BFGS', jac=rosen_der, options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999913 0.99999825]\n",
      "7.71728835853869e-13\n"
     ]
    }
   ],
   "source": [
    "print(res2.x)\n",
    "print(res2.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the Hessian Matrix \n",
    "def rosen_hess(x):\n",
    "    H = np.array([2, 2])   \n",
    "    H00 =  1200*x[0]**2 - 400*x[1] + 2\n",
    "    H11 =  200\n",
    "    H01 =  -400*x[0]\n",
    "    H10 =  -400*x[0]         \n",
    "    H = [[H00, H01],[H10, H11]]    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[-2  0]\n",
      "[[2, 0], [0, 200]]\n",
      " -------------------------------- \n",
      "7.71728835853869e-13\n",
      "[ 3.92841201e-06 -2.83120873e-06]\n",
      "[[801.9986184625773, -399.9996531998896], [-399.9996531998896, 200]]\n"
     ]
    }
   ],
   "source": [
    "# function, Gradient and Hessian at x = x0\n",
    "print (rosen(x0))\n",
    "print (rosen_der(x0))\n",
    "print (rosen_hess(x0))\n",
    "\n",
    "print (\" -------------------------------- \")\n",
    "# function, jacobian and Hessian at x = optimized point\n",
    "# note \n",
    "# the function is at the \"loacal\" minimum\n",
    "# the gradient vector is zero\n",
    "print (rosen(res2.x))\n",
    "print (rosen_der(res2.x))\n",
    "print (rosen_hess(res2.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 35\n",
      "         Function evaluations: 55\n",
      "         Gradient evaluations: 89\n",
      "         Hessian evaluations: 35\n"
     ]
    }
   ],
   "source": [
    "res3 = minimize(rosen, x0, method='Newton-CG',jac=rosen_der, hess=rosen_hess,options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (res3.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_Vector(x):\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_FirstDerivativeVector(x):\n",
    "    \"\"\"The Rosenbrock function derivative\"\"\"\n",
    "    xm = x[1:-1]\n",
    "    xm_m1 = x[:-2]\n",
    "    xm_p1 = x[2:]\n",
    "    der = np.zeros_like(x)\n",
    "    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
    "    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
    "    der[-1] = 200*(x[-1]-x[-2]**2)\n",
    "    return der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_SecondHessianMatrix(x):\n",
    "    x = np.asarray(x)\n",
    "    H = np.diag(-400*x[:-1],1) - np.diag(400*x[:-1],-1)\n",
    "    diagonal     = np.zeros_like(x)\n",
    "    diagonal[0]  = 1200*x[0]**2-400*x[1]+2\n",
    "    diagonal[-1] = 200\n",
    "    diagonal[1:-1] = 202 + 1200*x[1:-1]**2 - 400*x[2:]\n",
    "    H = H + np.diag(diagonal)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3 0.7 0.8 1.9 1.2]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "print (x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 339\n",
      "         Function evaluations: 571\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "res = minimize(rosen_Vector, x0, method='nelder-mead',options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848.22\n",
      "[ 515.4 -285.4 -341.6 2085.4 -482. ]\n",
      "[[1750. -520.    0.    0.    0.]\n",
      " [-520.  470. -280.    0.    0.]\n",
      " [   0. -280.  210. -320.    0.]\n",
      " [   0.    0. -320. 4054. -760.]\n",
      " [   0.    0.    0. -760.  200.]]\n",
      " ------------------------------------------------ \n",
      "4.861153433422115e-17\n",
      "[ 4.99059794e-08 -6.09594775e-08  2.66108494e-07 -8.84030519e-08\n",
      " -1.45017776e-08]\n",
      "[[ 802.0000007  -400.00000016    0.            0.            0.        ]\n",
      " [-400.00000016 1002.00000107 -400.00000028    0.            0.        ]\n",
      " [   0.         -400.00000028 1002.00000262 -400.00000059    0.        ]\n",
      " [   0.            0.         -400.00000059 1002.0000038  -400.00000094]\n",
      " [   0.            0.            0.         -400.00000094  200.        ]]\n"
     ]
    }
   ],
   "source": [
    "print (rosen_Vector(x0))\n",
    "print (rosen_FirstDerivativeVector(x0))\n",
    "print (rosen_SecondHessianMatrix(x0))\n",
    "\n",
    "print (\" ------------------------------------------------ \")\n",
    "print (rosen_Vector(res.x))\n",
    "print (rosen_FirstDerivativeVector(res.x)) # the gradient vector is zero!\n",
    "print (rosen_SecondHessianMatrix(res.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 25\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 30\n",
      "      fun: 4.0130879949972905e-13\n",
      " hess_inv: array([[0.00758796, 0.01243893, 0.02344025, 0.04614953, 0.09222281],\n",
      "       [0.01243893, 0.02481725, 0.04712952, 0.09298607, 0.18569385],\n",
      "       [0.02344025, 0.04712952, 0.09456412, 0.18674836, 0.37282072],\n",
      "       [0.04614953, 0.09298607, 0.18674836, 0.37383212, 0.74621435],\n",
      "       [0.09222281, 0.18569385, 0.37282072, 0.74621435, 1.49444705]])\n",
      "      jac: array([-5.68982937e-06, -2.73296557e-06, -2.54520599e-06, -7.73460770e-06,\n",
      "        5.78142698e-06])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 30\n",
      "      nit: 25\n",
      "     njev: 30\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([1.00000004, 1.0000001 , 1.00000021, 1.00000044, 1.00000092])\n"
     ]
    }
   ],
   "source": [
    "res2 = minimize(rosen_Vector, x0, method='BFGS', jac=rosen_FirstDerivativeVector, options={'disp': True})\n",
    "print (res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000004 1.0000001  1.00000021 1.00000044 1.00000092]\n",
      " ------------------------------------------------ \n",
      "4.0130879949972905e-13\n",
      "[-5.68982937e-06 -2.73296557e-06 -2.54520599e-06 -7.73460770e-06\n",
      "  5.78142698e-06]\n",
      "[[ 802.00006255 -400.00001708    0.            0.            0.        ]\n",
      " [-400.00001708 1002.00015393 -400.00003994    0.            0.        ]\n",
      " [   0.         -400.00003994 1002.00033689 -400.00008569    0.        ]\n",
      " [   0.            0.         -400.00008569 1002.00069752 -400.00017727]\n",
      " [   0.            0.            0.         -400.00017727  200.        ]]\n",
      "[[0.00741848 0.01237406 0.02357854 0.0466902  0.09338044]\n",
      " [0.01237406 0.02481    0.04727498 0.09361385 0.18722779]\n",
      " [0.02357854 0.04727498 0.0948453  0.18781252 0.3756252 ]\n",
      " [0.0466902  0.09361385 0.18781252 0.37685657 0.75371348]\n",
      " [0.09338044 0.18722779 0.3756252  0.75371348 1.51242763]]\n",
      " ------------------------------------------------ \n",
      "[[0.00758796 0.01243893 0.02344025 0.04614953 0.09222281]\n",
      " [0.01243893 0.02481725 0.04712952 0.09298607 0.18569385]\n",
      " [0.02344025 0.04712952 0.09456412 0.18674836 0.37282072]\n",
      " [0.04614953 0.09298607 0.18674836 0.37383212 0.74621435]\n",
      " [0.09222281 0.18569385 0.37282072 0.74621435 1.49444705]]\n"
     ]
    }
   ],
   "source": [
    "print (res2.x)\n",
    "print (\" ------------------------------------------------ \")\n",
    "print (rosen_Vector(res2.x))\n",
    "print (rosen_FirstDerivativeVector(res2.x))   # the Gradient vector matches the one from minimize output!\n",
    "\n",
    "from numpy.linalg import inv\n",
    "print (rosen_SecondHessianMatrix(res2.x))  \n",
    "print (inv(rosen_SecondHessianMatrix(res2.x)))# the Hassian Inverse is the same (or almost) \n",
    "\n",
    "#as the one from minimize output!\n",
    "print (\" ------------------------------------------------ \")\n",
    "print (res2.hess_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08710889 0.         0.         0.         0.        ]\n",
      " [0.14279747 0.06652918 0.         0.         0.        ]\n",
      " [0.26909133 0.13082924 0.07097662 0.         0.        ]\n",
      " [0.52979131 0.26053555 0.14230657 0.07087568 0.        ]\n",
      " [1.05870723 0.51876688 0.28265517 0.1402394  0.07004248]]\n",
      " ------------------------------------------- \n",
      "[[ 28.31960562   0.           0.           0.           0.        ]\n",
      " [-14.12449108  28.32841163   0.           0.           0.        ]\n",
      " [  0.         -14.12010123  28.33060321   0.           0.        ]\n",
      " [  0.           0.         -14.11901055  28.33115314   0.        ]\n",
      " [  0.           0.           0.         -14.11873972   0.81313508]]\n"
     ]
    }
   ],
   "source": [
    "# Positive definite (PD) matrices.\n",
    "# Cholesky decomposition is a good option if you're working with positive definite (PD) matrices.\n",
    "# Good test for positive definiteness (actually the standard one !) is to try to compute its Cholesky factorization. \n",
    "# It succeeds iff your matrix is positive definite.\n",
    "# However, it throws the following error on positive semi-definite (PSD) matrix\n",
    "\n",
    "# Positive definite (PD) matrices.\n",
    "print (np.linalg.cholesky(res2.hess_inv))\n",
    "print (\" ------------------------------------------- \")\n",
    "print (np.linalg.cholesky(rosen_SecondHessianMatrix(res2.x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0000e-04 8.0000e-04 1.4000e-03 3.1000e-03 1.9894e+00]\n",
      "[4.9730000e-01 3.5463040e+02 7.5459480e+02 1.2490982e+03 1.6491805e+03]\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# Positive Semi definite (PdD) matrices.\n",
    "# For PSD matrices, you can use scipy/numpy's eigh() to check that all eigenvalues are non-negative.\n",
    "E,V = scipy.linalg.eigh(res2.hess_inv)\n",
    "print (np.around(E, decimals=4, out=None))\n",
    "\n",
    "E,V = scipy.linalg.eigh(rosen_SecondHessianMatrix(res2.x))\n",
    "print (np.around(E, decimals=4, out=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 21\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 50\n",
      "         Hessian evaluations: 21\n",
      "[0.9999852  0.9999705  0.99994098 0.99988173 0.99976293]\n",
      "     fun: 1.859665471986481e-08\n",
      "     jac: array([ 5.86892970e-05,  1.54121807e-04,  6.93311785e-04,  3.04308913e-03,\n",
      "       -1.87051318e-03])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 30\n",
      "    nhev: 21\n",
      "     nit: 21\n",
      "    njev: 50\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.9999852 , 0.9999705 , 0.99994098, 0.99988173, 0.99976293])\n"
     ]
    }
   ],
   "source": [
    "res3 = minimize(rosen_Vector, x0, method='Newton-CG', jac=rosen_FirstDerivativeVector, \n",
    "                hess=rosen_SecondHessianMatrix, options={'disp': True})\n",
    "print (res3.x)\n",
    "print (res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.81376243e-05 -3.03701999e-05 -3.48177529e-05 -5.76854082e-05\n",
      " -1.11414771e-04]\n",
      "[[ 801.97628364 -399.9940805     0.            0.            0.        ]\n",
      " [-399.9940805  1001.95280859 -399.98819963    0.            0.        ]\n",
      " [   0.         -399.98819963 1001.90565171 -399.97639025    0.        ]\n",
      " [   0.            0.         -399.97639025 1001.81100993 -399.95269398]\n",
      " [   0.            0.            0.         -399.95269398  200.        ]]\n"
     ]
    }
   ],
   "source": [
    "print (rosen_FirstDerivativeVector(res3.x))\n",
    "print( rosen_SecondHessianMatrix(res3.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0130879949972905e-13\n",
      "1.859665471986481e-08\n"
     ]
    }
   ],
   "source": [
    "print (rosen_Vector(res2.x))\n",
    "print (rosen_Vector(res3.x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
